# ğŸ“‹ BÃO CÃO Lá»–I NGáº¦M VÃ€ PHÆ¯Æ NG ÃN GIáº¢I QUYáº¾T

> **NgÃ y:** 2025-12-23  
> **Má»¥c Ä‘Ã­ch:** PhÃ¢n tÃ­ch cÃ¡c lá»—i ngáº§m (hidden bugs) trong há»‡ thá»‘ng AI Chatbot

---

## ğŸ”´ DANH SÃCH Lá»–I NGáº¦M

### 1. âš ï¸ Preprocessing quÃ¡ aggressive cho KNN

**Váº¥n Ä‘á»:**
- NB vÃ  KNN dÃ¹ng chung `preprocess_text()` â†’ xÃ³a háº¿t stopwords nhÆ° `lÃ `, `gÃ¬`, `khÃ¡c`
- "KNN lÃ  gÃ¬" â†’ chá»‰ cÃ²n `knn` â†’ TF-IDF vector ráº¥t sparse
- Cosine similarity tháº¥p dÃ¹ cÃ¢u há»i Ä‘Ãºng chá»§ Ä‘á»

**Háº­u quáº£:**
- Confidence cá»§a KNN luÃ´n tháº¥p vá»›i cÃ¢u há»i ngáº¯n
- False negatives cao

**Giáº£i phÃ¡p Ä‘Ã£ implement:**
```python
# preprocess.py
def preprocess_for_knn(text):
    # DÃ¹ng LIGHT_STOPWORDS thay vÃ¬ VIETNAMESE_STOPWORDS
    # Giá»¯ CRITICAL_KEYWORDS (thuáº­t ngá»¯ AI/ML)
    # Má»Ÿ rá»™ng vá»›i synonyms
```

| TrÆ°á»›c | Sau |
|-------|-----|
| "KNN lÃ  gÃ¬" â†’ `knn` | "KNN lÃ  gÃ¬" â†’ `knn lÃ  gÃ¬ k-nearest neighbors lÃ¢n cáº­n gáº§n nháº¥t` |

---

### 2. âš ï¸ TF-IDF khÃ´ng capture semantic meaning

**Váº¥n Ä‘á»:**
- TF-IDF chá»‰ so sÃ¡nh tá»« â†’ "há»c mÃ¡y lÃ  gÃ¬" vs "machine learning lÃ  gÃ¬" â†’ similarity tháº¥p
- KhÃ´ng hiá»ƒu synonyms náº¿u khÃ´ng cÃ³ trong training data

**Háº­u quáº£:**
- CÃ¢u há»i paraphrase khÃ¡c nhau â†’ khÃ´ng tÃ¬m Ä‘Æ°á»£c cÃ¢u tráº£ lá»i Ä‘Ãºng

**Giáº£i phÃ¡p:**
1. âœ… **ÄÃ£ lÃ m:** Synonym expansion trong `preprocess_for_knn()`
2. ğŸ”® **Upgrade tÆ°Æ¡ng lai:** Word embeddings (Word2Vec, FastText) hoáº·c Sentence-BERT

---

### 3. âš ï¸ Confidence Calibration kÃ©m (ECE = 25.74%)

**Váº¥n Ä‘á»:**
- Expected Calibration Error cao: model "tá»± tin" hÆ¡n kháº£ nÄƒng thá»±c táº¿
- Náº¿u confidence = 70%, accuracy thá»±c táº¿ chá»‰ ~50%

**Háº­u quáº£:**
- User khÃ´ng thá»ƒ tin tÆ°á»Ÿng vÃ o confidence score
- KhÃ³ set threshold há»£p lÃ½

**Giáº£i phÃ¡p:**
1. **Temperature Scaling:** Äiá»u chá»‰nh logits báº±ng temperature parameter
   ```python
   calibrated_prob = softmax(logits / temperature)
   ```
2. **Platt Scaling:** Train logistic regression trÃªn validation set

---

### 4. âš ï¸ KhÃ´ng cÃ³ fallback khi confidence tháº¥p

**Váº¥n Ä‘á»:**
- Khi confidence < threshold, chatbot váº«n tráº£ vá» cÃ¢u "gáº§n nháº¥t" (cÃ³ thá»ƒ sai)
- KhÃ´ng phÃ¢n biá»‡t Ä‘Æ°á»£c "khÃ´ng hiá»ƒu" vs "hiá»ƒu nhÆ°ng khÃ´ng cháº¯c"

**Háº­u quáº£:**
- Tráº£ lá»i sai mÃ  khÃ´ng cáº£nh bÃ¡o user

**Giáº£i phÃ¡p:**
```python
def get_answer(question, threshold=0.5):
    answer, confidence = knn_predict(question)
    
    if confidence >= 0.7:
        return answer  # Confident
    elif confidence >= threshold:
        return f"(Äá»™ tin cáº­y: {confidence:.0%}) {answer}"  # Warning
    else:
        return "Xin lá»—i, tÃ´i khÃ´ng hiá»ƒu cÃ¢u há»i. Báº¡n cÃ³ thá»ƒ diá»…n Ä‘áº¡t láº¡i?"
```

---

### 5. âš ï¸ Data Imbalance giá»¯a cÃ¡c Topics

**Váº¥n Ä‘á»:**
- Má»™t sá»‘ topic cÃ³ nhiá»u Q&A, sá»‘ khÃ¡c ráº¥t Ã­t
- NB cÃ³ bias vá» topic phá»• biáº¿n

**Check data:**
```python
df['topic'].value_counts()
# VÃ­ dá»¥: MachineLearning: 500, Logic: 50 â†’ imbalance 10:1
```

**Giáº£i phÃ¡p:**
1. **Class weights:** TÄƒng weight cho topic thiá»ƒu sá»‘
   ```python
   from sklearn.utils.class_weight import compute_class_weight
   ```
2. **Oversampling:** Táº¡o thÃªm data cho topic Ã­t
3. **Stratified sampling:** Äáº£m báº£o validation set cÃ¢n báº±ng

---

### 6. âš ï¸ Training data vÃ  Validation data khÃ´ng cÃ¹ng distribution

**Váº¥n Ä‘á»:**
- Validation questions cÃ³ thá»ƒ Ä‘Æ°á»£c diá»…n Ä‘áº¡t khÃ¡c hoÃ n toÃ n vá»›i training
- KNN exact match = 0% (validation khÃ´ng cÃ³ cÃ¢u giá»‘ng training)

**Háº­u quáº£:**
- Metrics trÃªn validation khÃ´ng reflect production performance

**Giáº£i phÃ¡p:**
1. **Data augmentation:** Paraphrase training questions
2. **True semantic matching:** DÃ¹ng embedding thay vÃ¬ exact TF-IDF match
3. **Fuzzy matching metric:** Thay exact match báº±ng semantic similarity score

---

### 7. âš ï¸ MPS (Apple Silicon) chÆ°a Ä‘Æ°á»£c táº­n dá»¥ng

**Váº¥n Ä‘á»:**
- Code hiá»‡n táº¡i cháº¡y trÃªn CPU
- KhÃ´ng táº­n dá»¥ng Ä‘Æ°á»£c Metal Performance Shaders trÃªn M1/M2/M3

**Giáº£i phÃ¡p (cho deep learning models):**
```python
import torch
device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
model = model.to(device)
```

> ğŸ“Œ Vá»›i NB/KNN tá»« sklearn, CPU Ä‘á»§ nhanh. MPS chá»‰ cÃ³ Ã½ nghÄ©a khi dÃ¹ng PyTorch models.

---

## âœ… Tá»”NG Káº¾T

| Lá»—i | Má»©c Ä‘á»™ | Status |
|-----|--------|--------|
| Preprocessing cho KNN | ğŸ”´ High | âœ… ÄÃ£ fix |
| TF-IDF khÃ´ng semantic | ğŸŸ¡ Medium | âš ï¸ Cáº§n upgrade |
| Confidence calibration | ğŸŸ¡ Medium | ğŸ“ Äá» xuáº¥t |
| KhÃ´ng cÃ³ fallback | ğŸ”´ High | ğŸ“ Äá» xuáº¥t |
| Data imbalance | ğŸŸ¡ Medium | ğŸ“ Äá» xuáº¥t |
| Train/Val mismatch | ğŸŸ¡ Medium | ğŸ“ Äá» xuáº¥t |
| MPS acceleration | ğŸŸ¢ Low | ğŸ“ Optional |

---

*BÃ¡o cÃ¡o nÃ y Ä‘Æ°á»£c táº¡o tá»± Ä‘á»™ng bá»Ÿi evaluate_models.py*
