# -------------------------------
# ğŸ§  train_models.py â€” Huáº¥n luyá»‡n toÃ n bá»™ mÃ´ hÃ¬nh cho Chatbot
# Chá»©c nÄƒng:
#   - Äá»c dá»¯ liá»‡u Q&A tá»« cÆ¡ sá»Ÿ dá»¯ liá»‡u SQLite (knowledge.db)
#   - Tiá»n xá»­ lÃ½ vÄƒn báº£n (chuáº©n hÃ³a ngÃ´n ngá»¯)
#   - Huáº¥n luyá»‡n TF-IDF vectorizer, mÃ´ hÃ¬nh NaÃ¯ve Bayes, vÃ  KNN
#   - LÆ°u cÃ¡c mÃ´ hÃ¬nh ra thÆ° má»¥c "models/"
# -------------------------------

import pandas as pd
import pickle
from datastore import get_all_qa                  # Láº¥y dá»¯ liá»‡u Q&A tá»« database
from preprocess import preprocess_text, train_vectorizer
from nb_module import train_naive_bayes
from knn_module import train_knn

import nltk
import os

# -------------------------------
# ğŸ“¦ Táº¢I Dá»® LIá»†U Há»– TRá»¢ Tá»ª NLTK (láº§n Ä‘áº§u tiÃªn cháº¡y)
# -------------------------------
# CÃ¡c gÃ³i nÃ y giÃºp tokenization, stopwords filtering vÃ  lemmatization hoáº¡t Ä‘á»™ng chÃ­nh xÃ¡c.
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('punkt_tab')   # (bá»• sung Ä‘á»ƒ há»— trá»£ má»™t sá»‘ trÆ°á»ng há»£p Ä‘áº·c biá»‡t trong NLTK)

# -------------------------------
# ğŸ“ Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n thÆ° má»¥c lÆ°u mÃ´ hÃ¬nh
# -------------------------------
BASE_DIR = os.path.dirname(__file__)               # â†’ thÆ° má»¥c hiá»‡n táº¡i ("app/")
MODEL_DIR = os.path.join(BASE_DIR, '..', 'models') # â†’ lÃ¹i 1 cáº¥p Ä‘áº¿n thÆ° má»¥c "models/"
# os.makedirs(MODEL_DIR, exist_ok=True)            # Báº­t láº¡i náº¿u cáº§n tá»± Ä‘á»™ng táº¡o thÆ° má»¥c

# =========================================================
# ğŸš€ HÃ€M CHÃNH: HUáº¤N LUYá»†N TOÃ€N Bá»˜ MÃ” HÃŒNH CHATBOT
# =========================================================
def train_all_models():
    """
    âœ… Má»¥c Ä‘Ã­ch:
        - Äá»c toÃ n bá»™ dá»¯ liá»‡u Q&A tá»« knowledge.db
        - Tiá»n xá»­ lÃ½ vÄƒn báº£n
        - Huáº¥n luyá»‡n TF-IDF, NaÃ¯ve Bayes, vÃ  KNN
        - LÆ°u mÃ´ hÃ¬nh ra thÆ° má»¥c models/

    ğŸ” Káº¿t quáº£:
        models/
        â”œâ”€â”€ vectorizer.pkl
        â”œâ”€â”€ nb_model.pkl
        â””â”€â”€ knn_model.pkl
    """

    # ------------------------------------
    # 1ï¸âƒ£ Äá»c dá»¯ liá»‡u tá»« database
    # ------------------------------------
    print('ğŸ“š Äang Ä‘á»c dá»¯ liá»‡u tá»« knowledge.db...')
    df = get_all_qa()  # Tráº£ vá» DataFrame gá»“m [question, answer, topic]

    # Kiá»ƒm tra dá»¯ liá»‡u cÃ³ trá»‘ng khÃ´ng
    if df.empty:
        print('âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u trong cÆ¡ sá»Ÿ dá»¯ liá»‡u! Kiá»ƒm tra knowledge.db.')
        return

    # ------------------------------------
    # 2ï¸âƒ£ Tiá»n xá»­ lÃ½ dá»¯ liá»‡u vÄƒn báº£n
    # ------------------------------------
    # Gá»i hÃ m preprocess_text() cho tá»«ng cÃ¢u há»i
    #   - Chuyá»ƒn chá»¯ thÆ°á»ng
    #   - XÃ³a kÃ½ tá»± Ä‘áº·c biá»‡t, sá»‘, stopwords
    #   - Tokenize láº¡i thÃ nh vÄƒn báº£n sáº¡ch
    print('ğŸ§¹ Äang tiá»n xá»­ lÃ½ dá»¯ liá»‡u...')
    df['clean_text'] = df['question'].apply(preprocess_text)

    # ------------------------------------
    # 3ï¸âƒ£ Huáº¥n luyá»‡n TF-IDF vectorizer
    # ------------------------------------
    # TF-IDF sáº½ chuyá»ƒn tá»«ng cÃ¢u há»i thÃ nh vector sá»‘ há»c (Ä‘áº·c trÆ°ng)
    print('âš™ï¸ Äang huáº¥n luyá»‡n TF-IDF vectorizer...')
    vectorizer = train_vectorizer(df['clean_text'])

    # LÆ°u TF-IDF Ä‘Ã£ huáº¥n luyá»‡n Ä‘á»ƒ dÃ¹ng láº¡i khi dá»± Ä‘oÃ¡n
    with open(os.path.join(MODEL_DIR, 'vectorizer.pkl'), 'wb') as f:
        pickle.dump(vectorizer, f)

    # ------------------------------------
    # 4ï¸âƒ£ Huáº¥n luyá»‡n mÃ´ hÃ¬nh NaÃ¯ve Bayes
    # ------------------------------------
    # MÃ´ hÃ¬nh nÃ y há»c cÃ¡ch phÃ¢n loáº¡i cÃ¢u há»i vÃ o cÃ¡c chá»§ Ä‘á» (topics)
    print('ğŸ§  Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh NaÃ¯ve Bayes...')
    nb_model = train_naive_bayes(vectorizer, df['clean_text'], df['topic'])

    # ------------------------------------
    # 5ï¸âƒ£ Huáº¥n luyá»‡n mÃ´ hÃ¬nh KNN
    # ------------------------------------
    # MÃ´ hÃ¬nh nÃ y dÃ¹ng Ä‘á»ƒ tÃ¬m cÃ¢u há»i tÆ°Æ¡ng tá»± nháº¥t â†’ chá»n cÃ¢u tráº£ lá»i gáº§n nháº¥t
    print('ğŸ” Äang huáº¥n luyá»‡n mÃ´ hÃ¬nh KNN...')
    knn_model = train_knn(
        vectorizer,                # Bá»™ vector hÃ³a TF-IDF
        df['clean_text'],          # Dá»¯ liá»‡u huáº¥n luyá»‡n
        df['topic'],               # NhÃ£n chá»§ Ä‘á» (topic)
        n_neighbors=8              # Sá»‘ lÆ°á»£ng lÃ¡ng giá»ng gáº§n nháº¥t (k)
    )

    # ------------------------------------
    # 6ï¸âƒ£ Káº¿t thÃºc quÃ¡ trÃ¬nh huáº¥n luyá»‡n
    # ------------------------------------
    print('âœ… HoÃ n táº¥t huáº¥n luyá»‡n!')
    print('ğŸ“¦ CÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trong thÆ° má»¥c: models/')
    print('   â”œâ”€â”€ vectorizer.pkl')
    print('   â”œâ”€â”€ nb_model.pkl')
    print('   â””â”€â”€ knn_model.pkl')


# =========================================================
# â–¶ï¸ CHáº Y TRá»°C TIáº¾P FILE
# =========================================================
if __name__ == '__main__':
    # Khi cháº¡y file báº±ng lá»‡nh:
    #   python app/train_models.py
    # â†’ ToÃ n bá»™ quy trÃ¬nh huáº¥n luyá»‡n sáº½ Ä‘Æ°á»£c thá»±c hiá»‡n
    train_all_models()
