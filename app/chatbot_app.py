# -------------------------------
# ðŸ§  Chatbot há»c táº­p cho mÃ´n Nháº­p mÃ´n TrÃ­ tuá»‡ NhÃ¢n táº¡o (IT3160)
# File nÃ y lÃ  "main.py" â€“ file chÃ­nh khá»Ÿi cháº¡y á»©ng dá»¥ng Flask
# -------------------------------

# ðŸ“¦ Import cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
from flask import Flask, render_template, request, redirect, url_for  # Flask framework Ä‘á»ƒ xÃ¢y web app
import pandas as pd              # Xá»­ lÃ½ dá»¯ liá»‡u dáº¡ng báº£ng
import pickle                    # Äá»c file model Ä‘Ã£ lÆ°u (Naive Bayes, KNN, vectorizer)
from app.preprocess import preprocess_text       # HÃ m tiá»n xá»­ lÃ½ vÄƒn báº£n (loáº¡i bá» stopword, kÃ½ tá»± Ä‘áº·c biá»‡t...)
from app.nb_module import predict_topic          # HÃ m dá»± Ä‘oÃ¡n chá»§ Ä‘á» báº±ng mÃ´ hÃ¬nh NaÃ¯ve Bayes
from app.find_answer import find_best_answer      # HÃ m tÃ¬m cÃ¢u tráº£ lá»i gáº§n nháº¥t báº±ng KNN
from app.datastore import get_all_qa, get_qa_by_topic  # CÃ¡c hÃ m truy xuáº¥t dá»¯ liá»‡u Q&A tá»« SQLite
from app.m genai_module import generate_answer_with_ai # Module tÃ­ch há»£p Gemini AI
import os, sys                       # ThÆ° viá»‡n thao tÃ¡c vá»›i Ä‘Æ°á»ng dáº«n file/thÆ° má»¥c

# -------------------------------
# âš™ï¸ Thiáº¿t láº­p Ä‘Æ°á»ng dáº«n cho Flask
# -------------------------------

# BASE_DIR: Ä‘Æ°á»ng dáº«n tuyá»‡t Ä‘á»‘i tá»›i thÆ° má»¥c hiá»‡n táº¡i (thÆ° má»¥c "app/")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ROOT_DIR: lÃ¹i lÃªn má»™t cáº¥p (thÆ° má»¥c cha chá»©a "app", "templates", "static"â€¦)
ROOT_DIR = os.path.join(BASE_DIR, "..")

# -------------------------------
# ðŸš€ Khá»Ÿi táº¡o á»©ng dá»¥ng Flask
# -------------------------------
app = Flask(
    __name__,
    template_folder=os.path.join(ROOT_DIR, "templates"),  # ThÆ° má»¥c chá»©a file .html (Jinja2 templates)
    static_folder=os.path.join(ROOT_DIR, "static")        # ThÆ° má»¥c chá»©a CSS, JS, áº£nh, favicon, v.v.
)

# -------------------------------
# ðŸ“‚ Náº¡p mÃ´ hÃ¬nh há»c mÃ¡y Ä‘Ã£ huáº¥n luyá»‡n sáºµn
# -------------------------------

# vectorizer.pkl: mÃ´ hÃ¬nh chuyá»ƒn vÄƒn báº£n thÃ nh vector sá»‘ (TF-IDF, Bag-of-Words, v.v.)
with open('models/vectorizer.pkl', 'rb') as f:
    vectorizer = pickle.load(f)

# nb_model.pkl: mÃ´ hÃ¬nh NaÃ¯ve Bayes â†’ dÃ¹ng Ä‘á»ƒ dá»± Ä‘oÃ¡n chá»§ Ä‘á» (topic)
with open('models/nb_model.pkl', 'rb') as f:
    nb_model = pickle.load(f)

# knn_model.pkl: KHÃ”NG Sá»¬ Dá»¤NG (Ä‘Ã£ chuyá»ƒn sang Cosine Similarity)
# with open('models/knn_model.pkl', 'rb') as f:
#     knn_model = pickle.load(f)

# -------------------------------
# ðŸ’¬ Biáº¿n lÆ°u lá»‹ch sá»­ há»™i thoáº¡i
# -------------------------------
# LÆ°u táº¡m trong bá»™ nhá»› RAM (dáº¡ng list), sáº½ máº¥t khi reload server
chat_history = []


# -------------------------------
# ðŸŒ ROUTE CHÃNH: Trang Chatbot
# -------------------------------
@app.route('/', methods=['GET', 'POST'])
def chatbot():
    global chat_history

    if request.method == 'POST':
        user_message = request.form['user_message']

        if user_message.strip():
            # BÆ°á»›c 1: Tiá»n xá»­ lÃ½
            processed = preprocess_text(user_message)

            # BÆ°á»›c 2: Dá»± Ä‘oÃ¡n topic
            topic, topic_confidence = predict_topic(nb_model, vectorizer, processed)

            # BÆ°á»›c 3: Láº¥y cÃ¢u há»i trong topic
            df_topic = get_qa_by_topic(topic)

            # BÆ°á»›c 4: TÃ¬m best match vá»›i threshold
            result = find_best_answer(
                vectorizer,
                processed,  # âœ… DÃ¹ng processed thay vÃ¬ user_message
                df_topic,
                threshold=0.5  # âœ… NgÆ°á»¡ng confidence tá»‘i thiá»ƒu
            )

            answer, question_similarity, matched_question = result

            # âœ… TÃ­nh final confidence
            # âœ… TÃ­nh final confidence
            if answer is None:
                # Case 1: KhÃ´ng tÃ¬m tháº¥y cÃ¢u há»i nÃ o trong DB (do threshold cá»§a find_best_answer)
                final_confidence = 0.0
                print("DEBUG: answer is None -> final_confidence = 0.0")
            else:
                # Case 2: TÃ¬m tháº¥y, nhÆ°ng cáº§n kiá»ƒm tra Ä‘á»™ tin cáº­y tá»•ng há»£p
                # âœ… CÃ´ng thá»©c má»›i (NB-Centric): Naive Bayes quyáº¿t Ä‘á»‹nh chÃ­nh
                final_confidence = (
                    0.60 * topic_confidence +      # 60% - Naive Bayes quyáº¿t Ä‘á»‹nh chÃ­nh
                    0.30 * question_similarity +   # 30% - Há»— trá»£ tÃ¬m cÃ¢u tráº£ lá»i cá»¥ thá»ƒ
                    0.10 * 0.8                     # 10% - Yáº¿u tá»‘ khÃ¡c
                )
                print(f"DEBUG: Found answer. final_confidence = {final_confidence}")

            # ---------------------------------------------------------
            # ðŸ¤– QUYáº¾T Äá»ŠNH: DÃ¹ng cÃ¢u tráº£ lá»i tá»« DB hay gá»i AI?
            # ---------------------------------------------------------

            # NgÆ°á»¡ng Ä‘á»ƒ cháº¥p nháº­n cÃ¢u tráº£ lá»i tá»« DB (vÃ­ dá»¥: 0.55)
            CONFIDENCE_THRESHOLD = 0.55

            if final_confidence >= CONFIDENCE_THRESHOLD:
                # --- Äá»¦ Äá»˜ TIN Cáº¬Y ---
                print("DEBUG: Confidence >= Threshold. Using DB answer.")
                if final_confidence >= 0.80:
                    pass  # Ráº¥t tin cáº­y (>= 80%), khÃ´ng cáº§n disclaimer
                elif final_confidence >= 0.65:
                    answer += "\n\nðŸ’¡ Náº¿u cÃ¢u tráº£ lá»i chÆ°a chÃ­nh xÃ¡c, hÃ£y há»i chi tiáº¿t hÆ¡n."
                elif final_confidence >= 0.55:
                    answer += "\n\nâš ï¸ TÃ´i khÃ´ng hoÃ n toÃ n cháº¯c cháº¯n. Báº¡n cÃ³ thá»ƒ há»i theo cÃ¡ch khÃ¡c?"
            else:
                # --- KHÃ”NG Äá»¦ Äá»˜ TIN Cáº¬Y (hoáº·c khÃ´ng tÃ¬m tháº¥y) -> Gá»ŒI AI ---
                print(f"DEBUG: Confidence tháº¥p ({final_confidence:.2f}) < {CONFIDENCE_THRESHOLD}. Calling AI...")

                # Gá»i Google Gemini
                ai_answer = generate_answer_with_ai(user_message)
                print(f"DEBUG: AI Response: {ai_answer[:50]}..." if ai_answer else "DEBUG: AI Response is None/Empty")

                if ai_answer:
                    answer = ai_answer + "\n\nâœ¨ CÃ¢u tráº£ lá»i Ä‘Æ°á»£c sinh bá»Ÿi trÃ­ tuá»‡ nhÃ¢n táº¡o (Gemini)."

                    # GÃ¡n láº¡i confidence giáº£ Ä‘á»‹nh cho AI (Ä‘á»ƒ khÃ´ng bá»‹ coi lÃ  tháº¥p ná»¯a)
                    final_confidence = 0.9
                    topic = "AI_Generated"
                else:
                    # TrÆ°á»ng há»£p AI cÅ©ng lá»—i
                    print("DEBUG: AI failed. Using fallback error message.")
                    answer = "Xin lá»—i, tÃ´i khÃ´ng tÃ¬m tháº¥y cÃ¢u tráº£ lá»i vÃ  cÅ©ng khÃ´ng thá»ƒ káº¿t ná»‘i vá»›i AI lÃºc nÃ y."

            # âœ… LÆ°u kÃ¨m confidence (optional - Ä‘á»ƒ debug/analysis)
            chat_history.append({
                "user": user_message,
                "bot": answer,
                "confidence": round(final_confidence, 3),
                "topic": topic,
                "topic_conf": round(topic_confidence, 3),
                "question_sim": round(question_similarity, 3) if question_similarity else 0.0
            })

        return redirect(url_for('chatbot'))

    return render_template('index.html', chat_history=chat_history)


# -------------------------------
# ðŸ§¹ ROUTE PHá»¤: XÃ³a toÃ n bá»™ lá»‹ch sá»­ chat
# -------------------------------
@app.route('/clear', methods=['POST'])
def clear_history():
    """
    Khi ngÆ°á»i dÃ¹ng báº¥m nÃºt 'XÃ³a lá»‹ch sá»­' â†’ reset láº¡i danh sÃ¡ch chat_history
    """
    global chat_history
    chat_history = []  # LÃ m trá»‘ng danh sÃ¡ch há»™i thoáº¡i
    return redirect(url_for('chatbot'))  # Quay láº¡i trang chatbot chÃ­nh


# -------------------------------
# â–¶ï¸ Cháº¡y Flask app
# -------------------------------
if __name__ == '__main__':
    # debug=True giÃºp auto reload khi thay Ä‘á»•i code vÃ  hiá»ƒn thá»‹ log lá»—i chi tiáº¿t
    app.run(debug=True)
