# -------------------------------
# üß† Chatbot h·ªçc t·∫≠p cho m√¥n Nh·∫≠p m√¥n Tr√≠ tu·ªá Nh√¢n t·∫°o (IT3160)
# File n√†y l√† "main.py" ‚Äì file ch√≠nh kh·ªüi ch·∫°y ·ª©ng d·ª•ng Flask
# -------------------------------

# -------------------------------
# üì¶ Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
from flask import Flask, render_template, request, redirect, url_for  # Flask framework ƒë·ªÉ x√¢y web app
import pandas as pd              # X·ª≠ l√Ω d·ªØ li·ªáu d·∫°ng b·∫£ng
import pickle                    # ƒê·ªçc file model ƒë√£ l∆∞u (Naive Bayes, KNN, vectorizer)
import os                       # Th∆∞ vi·ªán thao t√°c v·ªõi ƒë∆∞·ªùng d·∫´n file/th∆∞ m·ª•c
import numpy as np

# Import TensorFlow cho Deep Learning (Safe Import)
try:
    import tensorflow as tf
    from tensorflow.keras.models import load_model
    from tensorflow.keras.preprocessing.sequence import pad_sequences
    TF_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è TensorFlow not found. Deep Learning features will be disabled.")
    TF_AVAILABLE = False

# Import c√°c module x·ª≠ l√Ω NLP
from preprocess import preprocess_text, expand_query, detect_negation, weighted_keyword_match # üÜï Module NLU ƒë√£ g·ªôp
from nb_module import predict_topic          # H√†m d·ª± ƒëo√°n ch·ªß ƒë·ªÅ
from find_answer import find_best_answer      # H√†m t√¨m c√¢u tr·∫£ l·ªùi
from datastore import get_all_qa, get_qa_by_topic  # C√°c h√†m truy xu·∫•t d·ªØ li·ªáu

# -------------------------------
# ‚öôÔ∏è Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n cho Flask
# -------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = os.path.join(BASE_DIR, "..")

# -------------------------------
# üöÄ Kh·ªüi t·∫°o ·ª©ng d·ª•ng Flask
# -------------------------------
app = Flask(
    __name__,
    template_folder=os.path.join(ROOT_DIR, "templates"),
    static_folder=os.path.join(ROOT_DIR, "static")
)

# -------------------------------
# üéõÔ∏è C·∫§U H√åNH M√î H√åNH (MODEL CONFIGURATION)
# -------------------------------
# Ch·ªâ b·∫≠t DL n·∫øu c√≥ th∆∞ vi·ªán TensorFlow V√Ä ng∆∞·ªùi d√πng mu·ªën d√πng
USE_DEEP_LEARNING = True if TF_AVAILABLE else False

# -------------------------------
# üìÇ N·∫°p m√¥ h√¨nh h·ªçc m√°y ƒë√£ hu·∫•n luy·ªán s·∫µn
# -------------------------------

# 1. Naive Bayes & TF-IDF (Lu√¥n n·∫°p l√†m fallback)
try:
    with open('models/vectorizer.pkl', 'rb') as f:
        vectorizer = pickle.load(f)
    with open('models/nb_model.pkl', 'rb') as f:
        nb_model = pickle.load(f)
    print("‚úÖ Loaded Naive Bayes model.")
except Exception as e:
    print(f"‚ö†Ô∏è Could not load Naive Bayes model: {e}")

# 2. Deep Learning (LSTM/GRU) - Ch·ªâ n·∫°p n·∫øu c·∫ßn ho·∫∑c file t·ªìn t·∫°i
dl_model = None
dl_tokenizer = None
dl_label_encoder = None

if USE_DEEP_LEARNING:
    try:
        dl_model = load_model('models/dl_model.h5')
        with open('models/tokenizer.pickle', 'rb') as f:
            dl_tokenizer = pickle.load(f)
        with open('models/label_encoder.pickle', 'rb') as f:
            dl_label_encoder = pickle.load(f)
        print("‚úÖ Loaded Deep Learning model.")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not load Deep Learning model: {e}")
        print("‚û°Ô∏è Switching back to Naive Bayes.")
        USE_DEEP_LEARNING = False

# =========================================================
# üß† ENSEMBLE PREDICTION (Soft Voting)
# =========================================================
def predict_ensemble(text):
    """
    K·∫øt h·ª£p k·∫øt qu·∫£ t·ª´ Naive Bayes v√† Deep Learning (n·∫øu c√≥).
    Chi·∫øn l∆∞·ª£c: Soft Voting (Trung b√¨nh c·ªông x√°c su·∫•t).
    """
    # 1. D·ª± ƒëo√°n b·∫±ng Naive Bayes (Lu√¥n kh·∫£ d·ª•ng)
    nb_probs = None
    if nb_model and vectorizer:
        try:
            # Preprocess ri√™ng cho NB
            expanded = expand_query(text)
            processed = preprocess_text(expanded)
            final_input = detect_negation(processed)

            X_nb = vectorizer.transform([final_input])
            nb_probs = nb_model.predict_proba(X_nb)[0]
            classes = nb_model.classes_
        except Exception as e:
            print(f"‚ö†Ô∏è NB Error: {e}")
            return "Unknown", 0.0

    # 2. D·ª± ƒëo√°n b·∫±ng Deep Learning (N·∫øu kh·∫£ d·ª•ng)
    dl_probs = None
    if USE_DEEP_LEARNING and dl_model and dl_tokenizer:
        try:
            # Preprocess ri√™ng cho DL
            expanded = expand_query(text)
            processed = preprocess_text(expanded)
            final_input = detect_negation(processed)
            
            seq = dl_tokenizer.texts_to_sequences([final_input])
            padded = pad_sequences(seq, maxlen=100) # Max len kh·ªõp v·ªõi l√∫c train
            
            dl_probs_raw = dl_model.predict(padded)[0]
            
            # Map DL probs sang ƒë√∫ng th·ª© t·ª± classes c·ªßa NB
            # (Gi·∫£ s·ª≠ LabelEncoder c·ªßa DL kh·ªõp v·ªõi classes c·ªßa NB - C·∫ßn ƒë·ªìng b·ªô)
            # ƒê·ªÉ an to√†n, ta d√πng LabelEncoder c·ªßa DL ƒë·ªÉ map t√™n class -> prob
            dl_class_map = {dl_label_encoder.inverse_transform([i])[0]: p for i, p in enumerate(dl_probs_raw)}
            
            # T·∫°o vector prob theo th·ª© t·ª± c·ªßa NB classes
            dl_probs = np.zeros(len(classes))
            for i, cls in enumerate(classes):
                dl_probs[i] = dl_class_map.get(cls, 0.0)
                
        except Exception as e:
            print(f"‚ö†Ô∏è DL Error: {e}")
            dl_probs = None

    # 3. K·∫øt h·ª£p (Ensemble)
    if dl_probs is not None:
        # Tr·ªçng s·ªë: NB (0.4) + DL (0.6) - ∆Øu ti√™n DL v√¨ hi·ªÉu ng·ªØ c·∫£nh t·ªët h∆°n
        final_probs = 0.4 * nb_probs + 0.6 * dl_probs
        print(f"ü§ñ Ensemble: NB({np.max(nb_probs):.2f}) + DL({np.max(dl_probs):.2f}) -> Final")
    else:
        # Fallback v·ªÅ NB 100%
        final_probs = nb_probs
        print(f"ü§ñ Ensemble: Only NB used ({np.max(nb_probs):.2f})")

    # 4. L·∫•y k·∫øt qu·∫£ cu·ªëi c√πng
    max_idx = np.argmax(final_probs)
    predicted_topic = classes[max_idx]
    confidence = final_probs[max_idx]
    
    return predicted_topic, confidence

# =========================================================
# üåê ROUTES
# =========================================================
@app.route("/")
def home():
    return render_template("index.html")

from inference_engine import inference_engine

@app.route("/get_response", methods=["POST"])
def chatbot():
                vectorizer, 
                final_input,  # ‚úÖ D√πng input ƒë√£ qua x·ª≠ l√Ω NLU
                df_topic, 
                original_query=user_message, # üÜï D√πng query g·ªëc cho Jaccard
                threshold=0.5
            )
            
            answer, question_similarity, matched_question = result
            
            # B∆∞·ªõc 4: T√≠nh ƒëi·ªÉm b·ªï sung t·ª´ t·ª´ kh√≥a tr·ªçng s·ªë (Weighted Keywords)
            keyword_score = weighted_keyword_match(user_message) # T√≠nh tr√™n message g·ªëc
            
            # ‚úÖ T√≠nh final confidence
            if answer is None:
                final_confidence = 0.0
            else:
                # C√¥ng th·ª©c m·ªõi c√≥ t√≠nh th√™m keyword_score (nh·∫π)
                base_conf = (0.60 * topic_confidence + 0.30 * question_similarity + 0.10 * 0.8)
                
                # Bonus ƒëi·ªÉm n·∫øu kh·ªõp t·ª´ kh√≥a quan tr·ªçng (t·ªëi ƒëa +0.1)
                bonus = min(keyword_score * 0.05, 0.1)
                final_confidence = min(base_conf + bonus, 1.0)
                
                print(f"DEBUG: Base Conf={base_conf:.2f}, Bonus={bonus:.2f} -> Final={final_confidence:.2f}")

            # ---------------------------------------------------------
            # ü§ñ QUY·∫æT ƒê·ªäNH TR·∫¢ L·ªúI (PURE NLU - NO GEN AI)
            # ---------------------------------------------------------
            CONFIDENCE_THRESHOLD = 0.55

            if final_confidence >= CONFIDENCE_THRESHOLD:
                # --- ƒê·ª¶ ƒê·ªò TIN C·∫¨Y ---
                if final_confidence >= 0.80:
                    pass
                elif final_confidence >= 0.65:
                    answer += "\n\nüí° (T√¥i kh√° ch·∫Øc ch·∫Øn v·ªÅ c√¢u tr·∫£ l·ªùi n√†y)"
                elif final_confidence >= 0.55:
                    answer += "\n\n‚ö†Ô∏è (T√¥i kh√¥ng ch·∫Øc l·∫Øm, b·∫°n ki·ªÉm tra l·∫°i nh√©)"
            else:
                # --- KH√îNG T√åM TH·∫§Y ---
                answer = "Xin l·ªói, t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n ho·∫∑c ch∆∞a ƒë∆∞·ª£c h·ªçc v·ªÅ v·∫•n ƒë·ªÅ n√†y. B·∫°n h√£y th·ª≠ di·ªÖn ƒë·∫°t l·∫°i xem sao?"
                topic = "Unknown"
            
            # L∆∞u l·ªãch s·ª≠
            chat_history.append({
                "user": user_message,
                "bot": answer,
                "confidence": round(final_confidence, 3),
                "topic": topic,
                "topic_conf": round(topic_confidence, 3),
                "question_sim": round(question_similarity, 3) if question_similarity else 0.0
            })
        
        return redirect(url_for('chatbot'))
    
    return render_template('index.html', chat_history=chat_history)


# -------------------------------
# üßπ ROUTE PH·ª§: X√≥a to√†n b·ªô l·ªãch s·ª≠ chat
# -------------------------------
@app.route('/clear', methods=['POST'])
def clear_history():
    global chat_history
    chat_history = []
    return redirect(url_for('chatbot'))


# -------------------------------
# ‚ñ∂Ô∏è Ch·∫°y Flask app
# -------------------------------
if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5002)
