# -------------------------------
# üîç knn_module.py ‚Äî K-Nearest Neighbors cho Chatbot
# Ch·ª©c nƒÉng: T√¨m c√¢u h·ªèi g·∫ßn nh·∫•t trong database b·∫±ng KNN
# Ch·∫°y song song v·ªõi Naive Bayes ƒë·ªÉ so s√°nh
# -------------------------------

import numpy as np
import pickle
import os

# -------------------------------
# üìÅ Thi·∫øt l·∫≠p ƒë∆∞·ªùng d·∫´n
# -------------------------------
BASE_DIR = os.path.dirname(__file__)
MODEL_DIR = os.path.join(BASE_DIR, '..', 'models')
KNN_MODEL_PATH = os.path.join(MODEL_DIR, 'knn_model.pkl')


# =========================================================
# üîÆ CLASS CUSTOM KNN (T·ª∞ VI·∫æT)
# =========================================================
class CustomKNN:
    """
    T·ª± c√†i ƒë·∫∑t thu·∫≠t to√°n K-Nearest Neighbors.
    D√πng ƒë·ªÉ t√¨m c√¢u h·ªèi trong database g·∫ßn nh·∫•t v·ªõi query c·ªßa user.
    
    üìå L∆∞u √Ω v·ªÅ Shape:
    - X_train: (n_samples, n_features) - Ma tr·∫≠n TF-IDF c·ªßa c√°c c√¢u h·ªèi
    - query: (1, n_features) ho·∫∑c (n_features,) - Vector TF-IDF c·ªßa c√¢u h·ªèi user
    """
    
    def __init__(self, k=5, metric='cosine'):
        """
        Kh·ªüi t·∫°o KNN.
        
        Args:
            k (int): S·ªë l√°ng gi·ªÅng g·∫ßn nh·∫•t ƒë·ªÉ xem x√©t
            metric (str): 'cosine' ho·∫∑c 'euclidean'
        """
        self.k = k
        self.metric = metric
        self.X_train = None       # TF-IDF vectors c·ªßa c√¢u h·ªèi   Shape: (n_samples, n_features)
        self.questions = None     # List c√¢u h·ªèi g·ªëc
        self.answers = None       # List c√¢u tr·∫£ l·ªùi t∆∞∆°ng ·ª©ng
        self.topics = None        # List topic t∆∞∆°ng ·ª©ng
        
    def fit(self, X, questions, answers, topics=None):
        """
        Fit model v·ªõi d·ªØ li·ªáu training.
        
        Args:
            X: Ma tr·∫≠n TF-IDF (sparse ho·∫∑c dense)  Shape: (n_samples, n_features)
            questions: List c√¢u h·ªèi
            answers: List c√¢u tr·∫£ l·ªùi
            topics: List topic (optional)
        """
        # Chuy·ªÉn sparse matrix sang dense n·∫øu c·∫ßn
        if hasattr(X, 'toarray'):
            self.X_train = X.toarray()  # Shape: (n_samples, n_features)
        else:
            self.X_train = np.array(X)
            
        self.questions = list(questions)
        self.answers = list(answers)
        self.topics = list(topics) if topics else [None] * len(questions)
        
        print(f"‚úÖ KNN fitted with {len(self.questions)} samples, shape: {self.X_train.shape}")
        return self
    
    def _compute_distance(self, vec1, vec2):
        """
        T√≠nh kho·∫£ng c√°ch gi·ªØa 2 vector.
        
        Args:
            vec1, vec2: Shape (n_features,)
            
        Returns:
            float: Kho·∫£ng c√°ch (c√†ng nh·ªè c√†ng gi·ªëng)
        """
        if self.metric == 'cosine':
            # Cosine Distance = 1 - Cosine Similarity
            norm1 = np.linalg.norm(vec1)
            norm2 = np.linalg.norm(vec2)
            if norm1 == 0 or norm2 == 0:
                return 1.0  # Max distance if zero vector
            similarity = np.dot(vec1, vec2) / (norm1 * norm2)
            return 1.0 - similarity
        else:
            # Euclidean Distance
            return np.linalg.norm(vec1 - vec2)
    
    def predict(self, query_vector, return_details=False):
        """
        T√¨m K c√¢u h·ªèi g·∫ßn nh·∫•t v·ªõi query.
        
        Args:
            query_vector: TF-IDF vector c·ªßa c√¢u h·ªèi user  Shape: (1, n_features) ho·∫∑c (n_features,)
            return_details: N·∫øu True, tr·∫£ v·ªÅ top K k·∫øt qu·∫£ chi ti·∫øt
            
        Returns:
            N·∫øu return_details=False: (best_answer, confidence, matched_question, topic)
            N·∫øu return_details=True: List[(distance, question, answer, topic)]
        """
        # Chu·∫©n h√≥a shape
        if hasattr(query_vector, 'toarray'):
            query_vector = query_vector.toarray()  # Sparse to dense
        query_vector = np.array(query_vector).flatten()  # Shape: (n_features,)
        
        # T√≠nh kho·∫£ng c√°ch ƒë·∫øn t·∫•t c·∫£ c√°c c√¢u h·ªèi trong training set
        distances = []
        for i in range(len(self.X_train)):
            dist = self._compute_distance(query_vector, self.X_train[i])
            distances.append({
                'distance': dist,
                'index': i,
                'question': self.questions[i],
                'answer': self.answers[i],
                'topic': self.topics[i]
            })
        
        # S·∫Øp x·∫øp theo kho·∫£ng c√°ch tƒÉng d·∫ßn (g·∫ßn nh·∫•t tr∆∞·ªõc)
        distances.sort(key=lambda x: x['distance'])
        
        # L·∫•y K nearest neighbors
        k_nearest = distances[:self.k]
        
        if return_details:
            return k_nearest
        
        # Tr·∫£ v·ªÅ c√¢u g·∫ßn nh·∫•t
        best = k_nearest[0]
        # Chuy·ªÉn distance th√†nh confidence: 0.0 (xa) -> 1.0 (g·∫ßn)
        # V·ªõi cosine distance, range l√† [0, 2], nh∆∞ng th∆∞·ªùng trong [0, 1]
        confidence = max(0, 1.0 - best['distance'])
        
        return best['answer'], confidence, best['question'], best['topic']
    
    def predict_voting(self, query_vector):
        """
        üÜï D·ª± ƒëo√°n b·∫±ng Weighted Voting t·ª´ K neighbors.
        
        Thay v√¨ ch·ªâ l·∫•y c√¢u g·∫ßn nh·∫•t, t√≠nh ƒëi·ªÉm cho t·ª´ng ƒë√°p √°n
        d·ª±a tr√™n kho·∫£ng c√°ch c·ªßa t·∫•t c·∫£ K neighbors.
        
        Args:
            query_vector: TF-IDF vector c·ªßa c√¢u h·ªèi user
            
        Returns:
            (best_answer, confidence, matched_question, topic)
        """
        # Chu·∫©n h√≥a shape
        if hasattr(query_vector, 'toarray'):
            query_vector = query_vector.toarray()
        query_vector = np.array(query_vector).flatten()
        
        # T√≠nh kho·∫£ng c√°ch ƒë·∫øn t·∫•t c·∫£ c√°c c√¢u h·ªèi
        distances = []
        for i in range(len(self.X_train)):
            dist = self._compute_distance(query_vector, self.X_train[i])
            distances.append({
                'distance': dist,
                'index': i,
                'question': self.questions[i],
                'answer': self.answers[i],
                'topic': self.topics[i],
                'weight': max(0, 1.0 - dist)  # Weight = similarity
            })
        
        # S·∫Øp x·∫øp v√† l·∫•y K nearest
        distances.sort(key=lambda x: x['distance'])
        k_nearest = distances[:self.k]
        
        # Weighted Voting: T·ªïng h·ª£p ƒëi·ªÉm cho m·ªói ƒë√°p √°n
        answer_scores = {}
        for neighbor in k_nearest:
            ans = neighbor['answer']
            weight = neighbor['weight']
            if ans not in answer_scores:
                answer_scores[ans] = {
                    'score': 0,
                    'question': neighbor['question'],
                    'topic': neighbor['topic'],
                    'count': 0
                }
            answer_scores[ans]['score'] += weight
            answer_scores[ans]['count'] += 1
        
        # Ch·ªçn ƒë√°p √°n c√≥ t·ªïng ƒëi·ªÉm cao nh·∫•t
        best_answer = max(answer_scores.keys(), key=lambda x: answer_scores[x]['score'])
        best_info = answer_scores[best_answer]
        
        # Confidence = t·ªïng ƒëi·ªÉm / s·ªë K (normalized)
        confidence = best_info['score'] / self.k
        
        return best_answer, confidence, best_info['question'], best_info['topic']
    
    def score(self, X_test, y_test):
        """
        ƒê√°nh gi√° accuracy tr√™n t·∫≠p test.
        
        Args:
            X_test: Shape (n_test, n_features)
            y_test: List c√¢u tr·∫£ l·ªùi ƒë√∫ng
        """
        if hasattr(X_test, 'toarray'):
            X_test = X_test.toarray()
        
        correct = 0
        for i in range(len(X_test)):
            pred_answer, _, _, _ = self.predict(X_test[i])
            if pred_answer == y_test[i]:
                correct += 1
        
        return correct / len(X_test)


# =========================================================
# üß† H√ÄM T√åM C√ÇU TR·∫¢ L·ªúI B·∫∞NG KNN
# =========================================================
def find_answer_knn(knn_model, vectorizer, user_question, k=3):
    """
    T√¨m c√¢u tr·∫£ l·ªùi cho c√¢u h·ªèi user b·∫±ng KNN.
    
    Args:
        knn_model: Model KNN ƒë√£ train
        vectorizer: TF-IDF vectorizer
        user_question: C√¢u h·ªèi ƒë√£ preprocess
        k: S·ªë k·∫øt qu·∫£ tr·∫£ v·ªÅ
        
    Returns:
        (best_answer, confidence, matched_question, topic, top_k_results)
    """
    # 1. Vector h√≥a c√¢u h·ªèi user
    query_vec = vectorizer.transform([user_question])  # Shape: (1, n_features)
    
    # 2. T√¨m K nearest neighbors
    knn_model.k = k
    results = knn_model.predict(query_vec, return_details=True)
    
    # 3. Tr·∫£ v·ªÅ k·∫øt qu·∫£ t·ªët nh·∫•t + chi ti·∫øt
    if results:
        best = results[0]
        confidence = max(0, 1.0 - best['distance'])
        return best['answer'], confidence, best['question'], best['topic'], results
    
    return None, 0.0, None, None, []


# =========================================================
# üîÑ H√ÄM TRAIN KNN MODEL
# =========================================================
def train_knn_model(vectorizer, train_questions, train_answers, train_topics, k=5):
    """
    Train v√† l∆∞u KNN model.
    
    Args:
        vectorizer: TF-IDF vectorizer ƒë√£ fit
        train_questions: List c√¢u h·ªèi
        train_answers: List c√¢u tr·∫£ l·ªùi
        train_topics: List topic
        k: S·ªë neighbors
        
    Returns:
        knn_model: Model ƒë√£ train
    """
    print("üîÑ Training KNN model...")
    
    # 1. Vector h√≥a c√¢u h·ªèi training
    X_train = vectorizer.transform(train_questions)  # Shape: (n_samples, n_features)
    
    # 2. T·∫°o v√† fit KNN
    knn = CustomKNN(k=k, metric='cosine')
    knn.fit(X_train, train_questions, train_answers, train_topics)
    
    # 3. L∆∞u model
    with open(KNN_MODEL_PATH, 'wb') as f:
        pickle.dump(knn, f)
    print(f"‚úÖ KNN model saved at: {os.path.abspath(KNN_MODEL_PATH)}")
    
    return knn


# =========================================================
# üß™ SANITY CHECK
# =========================================================
if __name__ == "__main__":
    print("\n--------- RUNNING KNN SANITY CHECK ---------\n")
    
    # 1. T·∫°o dummy data
    # Gi·∫£ l·∫≠p TF-IDF vectors (4 c√¢u h·ªèi, 3 features)
    X_dummy = np.array([
        [0.8, 0.1, 0.1],   # Q1: "BFS l√† g√¨"
        [0.2, 0.7, 0.1],   # Q2: "KNN l√† g√¨"
        [0.75, 0.15, 0.1], # Q3: "DFS l√† g√¨" (g·∫ßn Q1)
        [0.1, 0.1, 0.8],   # Q4: "Logic l√† g√¨"
    ])
    
    questions = ["BFS l√† g√¨", "KNN l√† g√¨", "DFS l√† g√¨", "Logic l√† g√¨"]
    answers = ["BFS l√† t√¨m theo chi·ªÅu r·ªông", "KNN l√† K l√°ng gi·ªÅng", 
               "DFS l√† t√¨m theo chi·ªÅu s√¢u", "Logic l√† m√¥n h·ªçc logic"]
    topics = ["Search", "ML", "Search", "Logic"]
    
    # 2. Train KNN
    knn = CustomKNN(k=2, metric='cosine')
    knn.fit(X_dummy, questions, answers, topics)  # Shape: (4, 3)
    
    # 3. Test query
    query = np.array([0.78, 0.12, 0.1])  # G·∫ßn gi·ªëng Q1 v√† Q3 (BFS, DFS)
    print(f"Query vector: {query}")
    print(f"Expected: G·∫ßn 'BFS l√† g√¨' ho·∫∑c 'DFS l√† g√¨'\n")
    
    results = knn.predict(query, return_details=True)
    print("Top K results:")
    for r in results:
        print(f"  Distance: {r['distance']:.4f} | Q: {r['question']} | Topic: {r['topic']}")
    
    print("\n‚úÖ KNN Sanity Check Passed!")
