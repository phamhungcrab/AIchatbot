# -------------------------------
# ğŸ“Š confidence_utils.py â€” Chuáº©n hoÃ¡ Confidence cho NB vÃ  KNN
# Má»¥c Ä‘Ã­ch: ÄÆ°a confidence cá»§a 2 models vá» cÃ¹ng má»™t scale cÃ´ng báº±ng
# -------------------------------

import numpy as np

# =========================================================
# ğŸ“ 1. LÃ THUYáº¾T CHUáº¨N HOÃ CONFIDENCE
# =========================================================
"""
Váº¤N Äá»€:
- NB confidence = max(P(topic|X)) â†’ thÆ°á»ng CAO (0.5 - 0.99) vÃ¬ softmax táº­p trung
- KNN confidence = 1 - cosine_distance â†’ thÆ°á»ng THáº¤P (0.2 - 0.6) vÃ¬ TF-IDF sparse

GIáº¢I PHÃP: Chuáº©n hoÃ¡ cáº£ 2 vá» scale [0, 1] cÃ´ng báº±ng

1. NB: Temperature Scaling
   - raw_conf cao quÃ¡ â†’ giáº£m báº±ng temperature > 1
   - calibrated = softmax(logits / temperature)

2. KNN: Sigmoid Scaling  
   - Chuyá»ƒn raw similarity vá» sigmoid curve
   - calibrated = 1 / (1 + exp(-k*(x - midpoint)))
"""


# =========================================================
# ğŸŒ¡ï¸ 2. NAIVE BAYES CALIBRATION
# =========================================================
class NaiveBayesCalibrator:
    """
    Chuáº©n hoÃ¡ confidence cho Naive Bayes báº±ng Temperature Scaling.
    
    ğŸ“Œ CÃ´ng thá»©c:
    1. Log Probability (tá»« NB):
       log P(c|X) = log P(c) + Î£ log P(word_i|c)
    
    2. Softmax vá»›i Temperature:
       P_calibrated(c|X) = exp(log P(c|X) / T) / Î£ exp(log P(k|X) / T)
    
    3. Confidence cuá»‘i:
       confidence = max(P_calibrated)
    
    ğŸ“Œ Ã nghÄ©a Temperature (T):
       - T = 1.0: Giá»¯ nguyÃªn (uncalibrated)
       - T > 1.0: "LÃ m má»m" distribution â†’ confidence tháº¥p hÆ¡n, Ä‘á»u hÆ¡n
       - T < 1.0: "LÃ m sáº¯c" distribution â†’ confidence cao hÆ¡n, táº­p trung hÆ¡n
    
    ğŸ“Œ CÃ¡ch chá»n T:
       - LÃ½ tÆ°á»Ÿng: Optimize trÃªn validation set Ä‘á»ƒ minimize ECE
       - Quick estimate: T â‰ˆ average_confidence / average_accuracy
    """
    
    def __init__(self, temperature=1.5):
        """
        Args:
            temperature: Há»‡ sá»‘ Ä‘iá»u chá»‰nh (T > 1 giáº£m confidence, T < 1 tÄƒng)
        """
        self.temperature = temperature
    
    def calibrate_from_logproba(self, log_probas):
        """
        Calibrate tá»« log probabilities (output cá»§a NB).
        
        Args:
            log_probas: np.array shape (n_classes,) - log P(c|X) cho má»—i class
            
        Returns:
            calibrated_confidence: float trong [0, 1]
            calibrated_proba: np.array shape (n_classes,) - xÃ¡c suáº¥t Ä‘Ã£ calibrate
        """
        # Chia cho temperature
        scaled_logits = log_probas / self.temperature  # Shape: (n_classes,)
        
        # Softmax vá»›i trick á»•n Ä‘á»‹nh sá»‘ há»c
        # P(c) = exp(z_c - max(z)) / Î£ exp(z_k - max(z))
        max_logit = np.max(scaled_logits)
        exp_logits = np.exp(scaled_logits - max_logit)  # Trá»« max Ä‘á»ƒ trÃ¡nh overflow
        calibrated_proba = exp_logits / np.sum(exp_logits)  # Shape: (n_classes,)
        
        # Confidence = max probability
        calibrated_confidence = float(np.max(calibrated_proba))
        
        return calibrated_confidence, calibrated_proba
    
    def calibrate_from_proba(self, raw_proba):
        """
        Calibrate tá»« raw probability (náº¿u Ä‘Ã£ cÃ³ softmax sáºµn).
        
        âš ï¸ LÆ°u Ã½: PhÆ°Æ¡ng phÃ¡p nÃ y lÃ  approximation, khÃ´ng chÃ­nh xÃ¡c báº±ng 
        calibrate_from_logproba vÃ¬ thÃ´ng tin log Ä‘Ã£ bá»‹ máº¥t.
        
        Args:
            raw_proba: np.array shape (n_classes,) - P(c|X) tá»« model
            
        Returns:
            calibrated_confidence: float trong [0, 1]
        """
        # Chuyá»ƒn vá» log, scale, rá»“i softmax láº¡i
        # ThÃªm epsilon Ä‘á»ƒ trÃ¡nh log(0)
        epsilon = 1e-10
        log_proba = np.log(raw_proba + epsilon)
        return self.calibrate_from_logproba(log_proba)
    
    def find_optimal_temperature(self, y_true, y_pred_proba, n_bins=10):
        """
        TÃ¬m temperature tá»‘i Æ°u Ä‘á»ƒ minimize ECE.
        
        Args:
            y_true: Ground truth labels
            y_pred_proba: Matrix of predicted probabilities (n_samples, n_classes)
            n_bins: Sá»‘ bins cho ECE
            
        Returns:
            optimal_temperature: float
        """
        best_t = 1.0
        best_ece = float('inf')
        
        for t in np.arange(0.5, 3.0, 0.1):
            self.temperature = t
            ece = self._calculate_ece(y_true, y_pred_proba, n_bins)
            if ece < best_ece:
                best_ece = ece
                best_t = t
        
        self.temperature = best_t
        return best_t
    
    def _calculate_ece(self, y_true, y_pred_proba, n_bins=10):
        """TÃ­nh Expected Calibration Error."""
        confidences = []
        predictions = []
        
        for proba in y_pred_proba:
            conf, _ = self.calibrate_from_proba(proba)
            confidences.append(conf)
            predictions.append(np.argmax(proba))
        
        confidences = np.array(confidences)
        predictions = np.array(predictions)
        correct = predictions == y_true
        
        bin_boundaries = np.linspace(0, 1, n_bins + 1)
        ece = 0.0
        
        for i in range(n_bins):
            in_bin = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i + 1])
            if np.sum(in_bin) > 0:
                bin_accuracy = np.mean(correct[in_bin])
                bin_confidence = np.mean(confidences[in_bin])
                bin_weight = np.sum(in_bin) / len(confidences)
                ece += bin_weight * abs(bin_accuracy - bin_confidence)
        
        return ece


# =========================================================
# ğŸ“ 3. KNN CALIBRATION
# =========================================================
class KNNCalibrator:
    """
    Chuáº©n hoÃ¡ confidence cho KNN báº±ng Sigmoid Scaling.
    
    ğŸ“Œ CÃ´ng thá»©c:
    1. Cosine Similarity (tá»« KNN):
       sim = 1 - cosine_distance = (AÂ·B) / (||A|| Ã— ||B||)
       â†’ ThÆ°á»ng trong khoáº£ng [0.2, 0.7] vá»›i TF-IDF
    
    2. Sigmoid Scaling:
       calibrated = 1 / (1 + exp(-k Ã— (sim - midpoint)))
       
       Trong Ä‘Ã³:
       - k: Äá»™ dá»‘c (steepness) - k lá»›n â†’ sigmoid sáº¯c hÆ¡n
       - midpoint: Äiá»ƒm uá»‘n - similarity = midpoint â†’ confidence = 0.5
    
    ğŸ“Œ Ã nghÄ©a tham sá»‘:
       - midpoint = 0.4: Similarity 0.4 â†’ Confidence 50%
       - k = 10: Sigmoid khÃ¡ dá»‘c, phÃ¢n biá»‡t rÃµ high/low similarity
    
    ğŸ“Œ Mapping máº«u (vá»›i k=10, midpoint=0.4):
       | Raw Sim | Calibrated |
       |---------|------------|
       | 0.2     | ~12%       |
       | 0.3     | ~27%       |
       | 0.4     | 50%        |
       | 0.5     | ~73%       |
       | 0.6     | ~88%       |
       | 0.7     | ~95%       |
    """
    
    def __init__(self, k=10.0, midpoint=0.4):
        """
        Args:
            k: Äá»™ dá»‘c sigmoid (steepness)
            midpoint: Äiá»ƒm similarity tÆ°Æ¡ng á»©ng vá»›i confidence 50%
        """
        self.k = k
        self.midpoint = midpoint
    
    def calibrate(self, raw_similarity):
        """
        Calibrate raw cosine similarity sang confidence chuáº©n hoÃ¡.
        
        Args:
            raw_similarity: float trong [0, 1] - cosine similarity gá»‘c
            
        Returns:
            calibrated_confidence: float trong [0, 1]
        """
        # Sigmoid function
        # Ïƒ(x) = 1 / (1 + exp(-k*(x - midpoint)))
        exponent = -self.k * (raw_similarity - self.midpoint)
        
        # Clamp exponent Ä‘á»ƒ trÃ¡nh overflow
        exponent = np.clip(exponent, -500, 500)
        
        calibrated = 1.0 / (1.0 + np.exp(exponent))
        
        return float(calibrated)
    
    def calibrate_batch(self, similarities):
        """Calibrate má»™t batch cÃ¡c similarity values."""
        return np.array([self.calibrate(s) for s in similarities])
    
    def find_optimal_params(self, similarities, correct_flags, target_ece=0.05):
        """
        TÃ¬m k vÃ  midpoint tá»‘i Æ°u dá»±a trÃªn validation data.
        
        Args:
            similarities: Array of raw similarities
            correct_flags: Boolean array - True náº¿u prediction Ä‘Ãºng
            target_ece: ECE má»¥c tiÃªu (default 5%)
            
        Returns:
            (optimal_k, optimal_midpoint)
        """
        best_k, best_mid = 10.0, 0.4
        best_ece = float('inf')
        
        for k in np.arange(5, 20, 1):
            for mid in np.arange(0.3, 0.6, 0.05):
                self.k = k
                self.midpoint = mid
                
                calibrated = self.calibrate_batch(similarities)
                ece = self._calculate_ece(correct_flags, calibrated)
                
                if ece < best_ece:
                    best_ece = ece
                    best_k, best_mid = k, mid
        
        self.k = best_k
        self.midpoint = best_mid
        return best_k, best_mid
    
    def _calculate_ece(self, correct_flags, confidences, n_bins=10):
        """TÃ­nh ECE cho KNN."""
        bin_boundaries = np.linspace(0, 1, n_bins + 1)
        ece = 0.0
        
        for i in range(n_bins):
            in_bin = (confidences > bin_boundaries[i]) & (confidences <= bin_boundaries[i + 1])
            if np.sum(in_bin) > 0:
                bin_accuracy = np.mean(correct_flags[in_bin])
                bin_confidence = np.mean(confidences[in_bin])
                bin_weight = np.sum(in_bin) / len(confidences)
                ece += bin_weight * abs(bin_accuracy - bin_confidence)
        
        return ece


# =========================================================
# ğŸ¯ 4. UNIFIED CALIBRATOR - INTERFACE CHUNG
# =========================================================
class UnifiedCalibrator:
    """
    Interface thá»‘ng nháº¥t Ä‘á»ƒ calibrate confidence cho cáº£ NB vÃ  KNN.
    
    ğŸ“Œ CÃ¡ch sá»­ dá»¥ng:
        calibrator = UnifiedCalibrator()
        
        # Calibrate NB
        nb_conf = calibrator.calibrate_nb(raw_nb_proba)
        
        # Calibrate KNN  
        knn_conf = calibrator.calibrate_knn(raw_cosine_similarity)
    """
    
    def __init__(self, nb_temperature=1.5, knn_k=10.0, knn_midpoint=0.4):
        self.nb_calibrator = NaiveBayesCalibrator(temperature=nb_temperature)
        self.knn_calibrator = KNNCalibrator(k=knn_k, midpoint=knn_midpoint)
    
    def calibrate_nb(self, raw_proba):
        """
        Calibrate NB confidence.
        
        Args:
            raw_proba: np.array hoáº·c list - xÃ¡c suáº¥t tá»« NB predict_proba
            
        Returns:
            float: Calibrated confidence
        """
        raw_proba = np.array(raw_proba).flatten()
        conf, _ = self.nb_calibrator.calibrate_from_proba(raw_proba)
        return conf
    
    def calibrate_knn(self, raw_similarity):
        """
        Calibrate KNN confidence.
        
        Args:
            raw_similarity: float - cosine similarity (1 - distance)
            
        Returns:
            float: Calibrated confidence
        """
        return self.knn_calibrator.calibrate(raw_similarity)
    
    def get_confidence_interpretation(self, confidence):
        """
        Diá»…n giáº£i confidence score.
        
        Args:
            confidence: float trong [0, 1]
            
        Returns:
            str: MÃ´ táº£ má»©c Ä‘á»™ tin cáº­y
        """
        if confidence >= 0.9:
            return "Ráº¥t cao (Very High) ğŸŸ¢"
        elif confidence >= 0.7:
            return "Cao (High) ğŸŸ¢"
        elif confidence >= 0.5:
            return "Trung bÃ¬nh (Medium) ğŸŸ¡"
        elif confidence >= 0.3:
            return "Tháº¥p (Low) ğŸŸ "
        else:
            return "Ráº¥t tháº¥p (Very Low) ğŸ”´"


# =========================================================
# ğŸ§ª SANITY CHECK
# =========================================================
if __name__ == "__main__":
    print("="*60)
    print("ğŸ§ª TEST CONFIDENCE CALIBRATION")
    print("="*60)
    
    # Khá»Ÿi táº¡o calibrator
    calibrator = UnifiedCalibrator(
        nb_temperature=1.5,
        knn_k=10.0,
        knn_midpoint=0.4
    )
    
    # Test NB calibration
    print("\nğŸ“Š NAIVE BAYES CALIBRATION (Temperature=1.5)")
    print("-"*60)
    test_nb_proba = [
        [0.8, 0.1, 0.1],    # Confidence cao
        [0.5, 0.3, 0.2],    # Confidence trung bÃ¬nh
        [0.4, 0.35, 0.25],  # Confidence tháº¥p
    ]
    
    print(f"{'Raw Proba':<30} {'Raw Conf':<12} {'Calibrated':<12}")
    for proba in test_nb_proba:
        raw_conf = max(proba)
        calibrated = calibrator.calibrate_nb(proba)
        print(f"{str(proba):<30} {raw_conf:<12.2%} {calibrated:<12.2%}")
    
    # Test KNN calibration
    print("\nğŸ” KNN CALIBRATION (k=10, midpoint=0.4)")
    print("-"*60)
    test_similarities = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]
    
    print(f"{'Raw Similarity':<18} {'Calibrated':<12} {'Level'}")
    for sim in test_similarities:
        calibrated = calibrator.calibrate_knn(sim)
        level = calibrator.get_confidence_interpretation(calibrated)
        print(f"{sim:<18.2f} {calibrated:<12.2%} {level}")
    
    print("\nâœ… Sanity check passed!")
